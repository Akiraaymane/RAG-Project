# RAG System Configuration
# Using Ollama for LLM

# Paths
paths:
  data_dir: "data"
  vector_store_dir: "vector_store"
  logs_dir: "logs"

# Document Processing
document_processing:
  chunk_size: 512
  chunk_overlap: 50
  split_method: "recursive"  # Options: markdown, recursive, character

# Embedding Model (Hugging Face)
embeddings:
  model_name: "sentence-transformers/all-MiniLM-L6-v2"
  device: "cuda"  # Use GPU for embeddings

# Vector Store
vector_store:
  type: "chroma"
  collection_name: "rag_documents"
  similarity_metric: "cosine"

# Retrieval
retrieval:
  top_k: 5
  score_threshold: 0.3

# LLM Configuration - Ollama
llm:
  provider: "ollama"
  model_name: "phi3.5"  # Your Ollama model (run: ollama pull phi3.5)
  base_url: "http://localhost:11434"  # Ollama server URL
  max_new_tokens: 512
  temperature: 0.7

# Chatbot
chatbot:
  max_history_length: 10
  system_message: "You are a helpful assistant that answers questions based on the provided documents about Transformers, BERT, and GPT-3."

# Evaluation
evaluation:
  metrics:
    - "faithfulness"
    - "answer_relevancy"
    - "context_precision"
    - "context_recall"

# Logging
logging:
  level: "INFO"
  format: "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
