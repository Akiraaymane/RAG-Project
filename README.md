# SystÃ¨me RAG (Retrieval-Augmented Generation)

Un systÃ¨me de gÃ©nÃ©ration de rÃ©ponses basÃ© sur la rÃ©cupÃ©ration d'informations, conÃ§u pour fournir des rÃ©ponses prÃ©cises Ã  partir d'un corpus de documents.

## ğŸš€ FonctionnalitÃ©s

- **Indexation de documents** : PrÃ©traitement et stockage efficace des documents
- **Recherche contextuelle** : RÃ©cupÃ©ration prÃ©cise des documents pertinents
- **GÃ©nÃ©ration de rÃ©ponses** : Production de rÃ©ponses naturelles basÃ©es sur le contexte
- **Ã‰valuation intÃ©grÃ©e** : Mesure des performances avec des mÃ©triques standardisÃ©es

## ï¿½ Configuration du ModÃ¨le

### TÃ©lÃ©chargement du ModÃ¨le Mistral

Ce projet utilise le modÃ¨le Mistral 7B. Suivez ces Ã©tapes pour le configurer :

1. **TÃ©lÃ©charger le modÃ¨le** :
   - [TÃ©lÃ©charger Mistral 7B](https://huggingface.co/mistralai/Mistral-7B-v0.1)
   - Cliquez sur "Files and versions" puis tÃ©lÃ©chargez tous les fichiers

2. **CrÃ©er le dossier des modÃ¨les** :
   ```bash
   mkdir -p models/mistral-7b
   ```

3. **Placer les fichiers** :
   - Extrayez les fichiers tÃ©lÃ©chargÃ©s dans `models/mistral-7b/`
   - La structure doit ressembler Ã  :
     ```
     models/
     â””â”€â”€ mistral-7b/
         â”œâ”€â”€ config.json
         â”œâ”€â”€ model.safetensors
         â”œâ”€â”€ tokenizer.json
         â””â”€â”€ ...
     ```

4. **VÃ©rifier la configuration** :
   Assurez-vous que le fichier `config/config_rag.yaml` contient :
   ```yaml
   llm:
     model_path: "./models/mistral-7b"
   ```

## ï¿½ğŸ“¦ PrÃ©requis

- Python 3.8+
- pip (gestionnaire de paquets Python)
- Un environnement virtuel Python (recommandÃ©)

## ğŸ›  Installation

1. **Cloner le dÃ©pÃ´t**
   ```bash
   git clone [https://github.com/Akiraaymane/RAG-Project.git]
   cd RAG-Project
   ```

2. **CrÃ©er et activer un environnement virtuel**
   ```bash
   python -m venv venv
   source venv/bin/activate  # Sur Windows: venv\Scripts\activate
   ```

3. **Installer les dÃ©pendances**
   ```bash
   pip install -r requirements.txt
   ```

## ğŸ— Structure du Projet

```
.
â”œâ”€â”€ config/                 # Fichiers de configuration
â”‚   â”œâ”€â”€ config_rag.yaml     # Configuration principale
â”‚   â””â”€â”€ eval_config.yaml   # Configuration de l'Ã©valuation
â”œâ”€â”€ data/                   # Dossier des donnÃ©es
â”‚   â”œâ”€â”€ raw/               # Documents bruts (PDF, TXT, etc.)
â”‚   â””â”€â”€ evaluation/        # DonnÃ©es pour l'Ã©valuation
â”œâ”€â”€ src/                   # Code source
â”‚   â”œâ”€â”€ evaluation/        # Module d'Ã©valuation
â”‚   â”œâ”€â”€ models/            # ModÃ¨les et logique mÃ©tier
â”‚   â””â”€â”€ utils/             # Utilitaires et helpers
â””â”€â”€ tests/                 # Tests unitaires et d'intÃ©gration
```

## ğŸš€ Utilisation

### Indexation des documents
```bash
python cli.py index --input-dir data/raw/
```

### Poser une question
```bash
python cli.py ask "Votre question ici"
```

### Ã‰valuer le systÃ¨me
```bash
python cli.py evaluate --test-data tests/fixtures/evaluation/test_set.json
```

## ğŸ“Š MÃ©triques d'Ã‰valuation

Le systÃ¨me fournit plusieurs mÃ©triques pour Ã©valuer les performances :

- **RÃ©cupÃ©ration** :
  - PrÃ©cision : Proportion de documents pertinents parmi ceux rÃ©cupÃ©rÃ©s
  - Rappel : Proportion de documents pertinents effectivement rÃ©cupÃ©rÃ©s
  - F1-score : Moyenne harmonique de la prÃ©cision et du rappel

- **GÃ©nÃ©ration** :
  - Exact Match : Pourcentage de rÃ©ponses identiques Ã  la rÃ©fÃ©rence
  - Score BLEU : Ã‰valuation de la qualitÃ© de la traduction
  - Score ROUGE : Mesure de similaritÃ© avec la rÃ©fÃ©rence

## ğŸ¤ Contribution

1. Forkez le projet
2. CrÃ©ez votre branche (`git checkout -b feature/AmazingFeature`)
3. Committez vos changements (`git commit -m 'Add some AmazingFeature'`)
4. Poussez vers la branche (`git push origin feature/AmazingFeature`)
5. Ouvrez une Pull Request

## ğŸ“„ Licence

Ce projet est sous licence MIT - voir le fichier `LICENSE` pour plus de dÃ©tails.

## ğŸ“ Contact

Pour toute question, veuillez ouvrir une issue sur le dÃ©pÃ´t.
